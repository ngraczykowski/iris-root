spark:
  master: ${S8_SPARK_MASTER:local[6]}
  app-name: ${S8_SPARK_APP_NAME:main-pipeline}
  config:
    'spark.executor.memory': ${S8_SPARK_EXECUTOR_MEMORY:512m}
    'spark.driver.memory': ${S8_SPARK_DRIVER_MEMORY:2g}
    #'spark.jars.packages': com.databricks:spark-xml_2.12:0.11.0 ?
    'spark.jars.packages': io.delta:delta-core_2.12:0.8.0
    'spark.sql.extensions': io.delta.sql.DeltaSparkSessionExtension
    'spark.sql.catalog.spark_catalog': org.apache.spark.sql.delta.catalog.DeltaCatalog

   # for a moment this is not working - causing spark session to recreate
   # 'spark.jars.ivy': $POV_HOME/aia-notebooks/dependencies/ivy2

#    'spark.local.dir': '/app/tmp'
#    'spark.executor.extraJavaOptions': '-Djava.io.tmpdir=/app/tmp'
#    'spark.driver.extraJavaOptions': '-Djava.io.tmpdir=/app/tmp'

#agents-call: serp
agents-call: standalone

serp:
  python_client:
    cert:
      user_chain: ${SERP_HOME}/cert/user/user-chain.pem
      user_key: ${SERP_HOME}/cert/user/user-key.pem
      ca_certs: ${SERP_HOME}/cert/ca-certs.pem
    consul:
      host: localhost
      port: 24120

tmp_dir: tmp

agents:
  name:
    jar: ../agents_jars/name-agent-dist-3.10.0/lib/*.jar
    port: 24301

  country: 
    jar: ../agents_jars/country-agent-dist-2.10.0/lib/*.jar
    port: 24315
    
  date: 
    jar: ../agents_jars/date-agent-dist-1.10.0/lib/*.jar
    port: 24313

  gender: 
    jar: ../agents_jars/gender-agent-dist-1.7.0/lib/*.jar
    port: 24311

  geo: 
    jar: ../agents_jars/geo-agent-dist-1.5.0-BUILD.152/lib/*.jar
    port: 24317
  
  document: 
    jar: ../agents_jars/document-number-agent-dist-2.16.0-BUILD.8/lib/*.jar
    port: 24309


customer_specific:

  csv_options:
    quote: '"'
    escape: '"'
    delimiter: ','
    lineterminator: "\n"
