{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd69b4c-19cf-48f7-a810-a4890e66302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CONFIG_APP_DIR\"] = \"tests/test_custom/config_app/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c549e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from etl_pipeline.config import alert_agents_config\n",
    "from etl_pipeline.config import columns_namespace as cn\n",
    "from etl_pipeline.custom.ms.datatypes.field import InputRecordField\n",
    "from etl_pipeline.custom.ms.payload_loader import PayloadLoader\n",
    "from etl_pipeline.custom.ms.transformations import (\n",
    "    create_agent_input_agg_col_config,\n",
    "    prepend_agent_name_to_ap_or_wl_or_aliases_key,\n",
    ")\n",
    "from etl_pipeline.custom.ms.watchlist_extractor import WatchlistExtractor\n",
    "from etl_pipeline.pipeline import ETLPipeline\n",
    "\n",
    "\n",
    "class MSPipeline(ETLPipeline):\n",
    "    def convert_raw_to_standardized(self, df):\n",
    "        return df\n",
    "    \n",
    "    def connect_input_record_with_match_record(self, payload):\n",
    "        for input_record in payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST]:\n",
    "            input_record['INPUT_FIELD'] = {\n",
    "                i[\"name\"]: InputRecordField(**i)\n",
    "                for i in input_record['field']\n",
    "            }\n",
    "            \n",
    "        new_payloads = []\n",
    "        for input_record in payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST]:\n",
    "            for match_record in payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]:\n",
    "                if input_record['versionId'] ==  match_record['inputVersionId']:\n",
    "                    pair_payload = deepcopy(payload)\n",
    "                    for num, input_record_to_remove in enumerate(payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST]):\n",
    "                        if input_record['versionId'] !=  input_record_to_remove['versionId']:\n",
    "                            del pair_payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST][num]\n",
    "                                \n",
    "                    for num, match_record_to_remove in  enumerate(payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]):\n",
    "                        if match_record['inputVersionId'] !=  match_record_to_remove['inputVersionId']:\n",
    "                            del pair_payload[cn.ALERT_FIELD][cn.MATCH_RECORDS][num]\n",
    "                            \n",
    "                    new_payloads.append(pair_payload)\n",
    "                    \n",
    "        return new_payloads        \n",
    "        \n",
    "    def transform_standardized_to_cleansed(self, payload):\n",
    "        match_ids = payload[cn.MATCH_IDS]\n",
    "        matches = payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "\n",
    "        parties = payload[cn.SUPPLEMENTAL_INFO][cn.RELATED_PARTIES][cn.PARTIES]\n",
    "\n",
    "        for num, party in enumerate(parties):\n",
    "            parties[num] = party[\"fields\"]\n",
    "                   \n",
    "        new_payloads = self.connect_input_record_with_match_record(payload)\n",
    "        \n",
    "        for payload in new_payloads:\n",
    "            fields = payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST][0][\"INPUT_FIELD\"]\n",
    "            for match_id in match_ids:\n",
    "                match = matches[match_id]\n",
    "                WatchlistExtractor().update_match_with_wl_values(match)\n",
    "                match[cn.TRIGGERED_BY] = self.engine.set_trigger_reasons(\n",
    "                    match, self.pipeline_config.FUZZINESS_LEVEL\n",
    "                )\n",
    "                self.engine.set_beneficiary_hits(match)\n",
    "\n",
    "            self.engine.connect_full_names(parties)\n",
    "\n",
    "            self.engine.collect_party_values(parties, payload)\n",
    "            payload[cn.ALL_CONNECTED_PARTY_TYPES] = payload[cn.ALL_PARTY_TYPES]\n",
    "            names_source_cols = [\n",
    "                cn.ALL_PARTY_NAMES,\n",
    "                cn.ALL_CONNECTED_PARTIES_NAMES,\n",
    "            ]\n",
    "\n",
    "            payload.update(\n",
    "                {\n",
    "                    cn.CLEANED_NAMES: self.engine.get_clean_names_from_concat_name(\n",
    "                        fields.get(cn.CONCAT_ADDRESS, None).value,\n",
    "                        {key: payload[key] for key in names_source_cols},\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "            payload.update({cn.CONCAT_RESIDUE: payload[cn.CLEANED_NAMES][cn.CONCAT_RESIDUE]})\n",
    "\n",
    "            concat_residue = payload[cn.CONCAT_RESIDUE]\n",
    "            concat_address = fields.get(cn.CONCAT_ADDRESS, None).value\n",
    "\n",
    "            payload.update({cn.CONCAT_ADDRESS_NO_CHANGES: concat_residue == concat_address})\n",
    "            for match_id in match_ids:\n",
    "                match = matches[match_id]\n",
    "                match[cn.AP_TRIGGERS] = self.engine.set_triggered_tokens_discovery(\n",
    "                    payload, match, fields\n",
    "                )\n",
    "\n",
    "        return new_payloads\n",
    "\n",
    "    def get_key(self, payload, match, conf):\n",
    "        new_config = {}\n",
    "        for key, value in dict(conf).items():\n",
    "            temp_dict = dict(value)\n",
    "            for new_key in temp_dict:\n",
    "                for element in temp_dict[new_key]:\n",
    "                    elements = element.split(\".\")\n",
    "                    if cn.MATCH_RECORDS in element:\n",
    "                        value = match\n",
    "                        elements = elements[1:]\n",
    "                    else:\n",
    "                        value = payload\n",
    "\n",
    "                    for field_name in elements:\n",
    "                        if field_name == \"INPUT_FIELD\":\n",
    "                            value = value[0][field_name][elements[-1]].value\n",
    "                            break\n",
    "                        try:\n",
    "                            value = value.get(field_name, None)\n",
    "                        except TypeError:\n",
    "                            key = PayloadLoader.LIST_ELEMENT_REGEX.sub(\"\", field_name)\n",
    "                            ix = int(PayloadLoader.LIST_ELEMENT_REGEX.match(field_name).groups(0))\n",
    "                            value = value[key][ix]\n",
    "                    new_config[elements[-1]] = value\n",
    "        return new_config\n",
    "\n",
    "    def load_agent_config(self, alert_type=\"WM_ADDRESS\"):\n",
    "        alert_config = alert_agents_config[alert_type]\n",
    "        parsed_agent_config = {}\n",
    "        for agent_name, agent_config in dict(alert_config).items():\n",
    "            particular_agent_config = dict(agent_config)\n",
    "            parsed_agent_config[agent_name] = {}\n",
    "            for new_key in particular_agent_config:\n",
    "                parsed_agent_config[agent_name][new_key] = []\n",
    "                for element in particular_agent_config[new_key]:\n",
    "                    elements = element.split(\".\")\n",
    "                    parsed_agent_config[agent_name][new_key].append(elements[-1])\n",
    "        return parsed_agent_config, alert_config\n",
    "\n",
    "    def transform_cleansed_to_application(self, payload):\n",
    "        import pdb; pdb.set_trace()\n",
    "        new_payloads = payload\n",
    "        for payload in new_payloads:\n",
    "            match_ids = payload[cn.MATCH_IDS]\n",
    "            matches = payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "            agent_config, yaml_conf = self.load_agent_config()\n",
    "            agent_input_prepended_agent_name_config = prepend_agent_name_to_ap_or_wl_or_aliases_key(\n",
    "                agent_config\n",
    "            )\n",
    "            \n",
    "            agent_input_agg_col_config = create_agent_input_agg_col_config(\n",
    "                agent_input_prepended_agent_name_config\n",
    "            )\n",
    "\n",
    "            for match_id in match_ids:\n",
    "                match = matches[match_id]\n",
    "                config = self.get_key(payload, match, yaml_conf)\n",
    "                self.engine.sql_to_merge_specific_columns_to_standardized(\n",
    "                    agent_input_prepended_agent_name_config,\n",
    "                    match,\n",
    "                    config,\n",
    "                    False,\n",
    "                )\n",
    "                config.update(\n",
    "                    {\n",
    "                        key: match.get(key)\n",
    "                        for key in match\n",
    "                        if key.endswith(\"_ap\") or key.endswith(\"_wl\")\n",
    "                    }\n",
    "                )\n",
    "                self.engine.sql_to_merge_specific_columns_to_standardized(\n",
    "                    agent_input_agg_col_config, match, config, True\n",
    "                )\n",
    "\n",
    "        return new_payloads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c16dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alert():\n",
    "    with open(\"API/alert.json\", \"r\") as f:\n",
    "        text = json.load(f)\n",
    "        match1 = Match(match_id=\"0\", match_name=\"1\")\n",
    "        match2 = Match(match_id=\"1\", match_name=\"2\")\n",
    "        alert = Alert(batch_id=\"1\", alert_name=\"2\", matches=[match1, match2])\n",
    "        for key, value in text.items():\n",
    "            alert.flat_payload[str(key)] = str(value)\n",
    "    return alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565d811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert = load_alert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c804420b-9569-449e-99b4-8d707bc9b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = load_alert()\n",
    "payload = payload.flat_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a181000-7737-4795-9b6c-952e82a16dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_json = {key: payload[key] for key in sorted(payload)}\n",
    "payload_json = PayloadLoader().load_payload_from_json(payload_json)\n",
    "payload_json['match_ids'] = [int(i.match_id) for i in alert.matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4621cef-444c-4155-b919-13ae516b6f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['headerInfo', 'inputRecordHist', 'matchRecords', 'supplementalInfo'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_json['alert'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec7eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = JsonProcessingEngine(pipeline_config)\n",
    "pipeline = MSPipeline(engine, config=pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef12fb5-1a45-4a5c-95ef-87f6d4d6a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payload = pipeline.transform_standardized_to_cleansed(payload_json)\n",
    "payload = pipeline.transform_cleansed_to_application(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a626d1-bac1-41e3-ae8a-cf91c32d99ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "190aa3c5-9909-4b36-b627-b72f22a7e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++\n",
      "[['', '10/10/1969']] [[]]\n",
      "[None] [[[], [], [], None, None]]\n",
      "[None] [None]\n",
      "++++++++\n",
      "[['', '10/10/1969']] [['01/11/1924']]\n",
      "[None] [[['CHIC'], [], [], None, None]]\n",
      "[None] [None]\n"
     ]
    }
   ],
   "source": [
    "for match in payload[\"alert\"][\"matchRecords\"]:\n",
    "    print(\"++++++++\")\n",
    "    print(match[\"ap_all_dobs_aggregated\"], match[\"wl_all_dobs_aggregated\"])\n",
    "    print(match[\"ap_all_nationalities_aggregated\"], match[\"wl_all_nationalities_aggregated\"])\n",
    "    print(match[\"ap_all_residencies_aggregated\"], match[\"wl_all_residencies_aggregated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f2d75-9de4-4b03-a0e6-5dc9897ba80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_json listy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
