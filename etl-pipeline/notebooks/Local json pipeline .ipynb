{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd69b4c-19cf-48f7-a810-a4890e66302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CONFIG_APP_DIR\"] = \"tests/test_custom/config_app/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c549e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "os.chdir(\"..\")\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import json\n",
    "from etl_pipeline.data_processor_engine.json_engine.json_engine import JsonProcessingEngine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522650c7-af7a-4824-8d36-bf62f558577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl_pipeline.config import columns_namespace as cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565d811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alert = load_alert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c804420b-9569-449e-99b4-8d707bc9b956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# payload = load_alert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82153271-8b29-42f9-9ca8-4d3f7ba2b721",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f813cf33-f0e2-48d6-92ff-3163cf5db3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from tkinter import E\n",
    "\n",
    "from etl_pipeline.config import alert_agents_config\n",
    "from etl_pipeline.config import columns_namespace as cn\n",
    "from etl_pipeline.custom.ms.datatypes.field import InputRecordField\n",
    "from etl_pipeline.custom.ms.payload_loader import PayloadLoader\n",
    "from etl_pipeline.custom.ms.transformations import (\n",
    "    create_agent_input_agg_col_config,\n",
    "    prepend_agent_name_to_ap_or_wl_or_aliases_key,\n",
    ")\n",
    "from etl_pipeline.custom.ms.watchlist_extractor import WatchlistExtractor\n",
    "from etl_pipeline.pipeline import ETLPipeline\n",
    "\n",
    "\n",
    "class MSPipeline(ETLPipeline):\n",
    "    def convert_raw_to_standardized(self, df):\n",
    "        return df\n",
    "\n",
    "    def flatten_parties(self, parties):\n",
    "        for num, party in enumerate(parties):\n",
    "            parties[num] = party[\"fields\"]\n",
    "\n",
    "    def parse_input_records(self, payload):\n",
    "        for input_record in payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST]:\n",
    "            input_record[\"INPUT_FIELD\"] = {\n",
    "                i[\"name\"]: InputRecordField(**i) for i in input_record[\"field\"]\n",
    "            }\n",
    "\n",
    "    def connect_input_record_with_match_record(self, payload):\n",
    "        new_payloads = []\n",
    "        for input_record in payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST]:\n",
    "            for match_record in payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]:\n",
    "                if input_record[\"versionId\"] == match_record[\"inputVersionId\"]:\n",
    "                    pair_payload = deepcopy(payload)\n",
    "                    for num, input_record_to_remove in enumerate(\n",
    "                        payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST]\n",
    "                    ):\n",
    "                        if input_record[\"versionId\"] != input_record_to_remove[\"versionId\"]:\n",
    "                            pair_payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST][num] = None\n",
    "\n",
    "                    for num, match_record_to_remove in enumerate(\n",
    "                        payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "                    ):\n",
    "                        if (\n",
    "                            match_record[\"inputVersionId\"]\n",
    "                            != match_record_to_remove[\"inputVersionId\"]\n",
    "                        ):\n",
    "                            pair_payload[cn.ALERT_FIELD][cn.MATCH_RECORDS][num] = None\n",
    "\n",
    "                    pair_payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST] = [\n",
    "                        elem for elem in pair_payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST] if elem\n",
    "                    ]\n",
    "                    pair_payload[cn.ALERT_FIELD][cn.MATCH_RECORDS] = [\n",
    "                        elem for elem in pair_payload[cn.ALERT_FIELD][cn.MATCH_RECORDS] if elem\n",
    "                    ]\n",
    "\n",
    "                    new_payloads.append(pair_payload)\n",
    "\n",
    "        return new_payloads\n",
    "\n",
    "    def transform_standardized_to_cleansed(self, payloads):\n",
    "        parties = payloads[cn.SUPPLEMENTAL_INFO][cn.RELATED_PARTIES][cn.PARTIES]\n",
    "        self.flatten_parties(parties)\n",
    "        self.parse_input_records(payloads)\n",
    "\n",
    "        payloads = self.connect_input_record_with_match_record(payloads)\n",
    "\n",
    "        for payload in payloads:\n",
    "            matches = payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "            fields = payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST][0][\"INPUT_FIELD\"]\n",
    "            for match in matches:\n",
    "                WatchlistExtractor().update_match_with_wl_values(match)\n",
    "                match[cn.TRIGGERED_BY] = self.engine.set_trigger_reasons(\n",
    "                    match, self.pipeline_config.FUZZINESS_LEVEL\n",
    "                )\n",
    "                self.engine.set_beneficiary_hits(match)\n",
    "\n",
    "            self.engine.connect_full_names(parties)\n",
    "\n",
    "            self.engine.collect_party_values(parties, payload)\n",
    "            payload[cn.ALL_CONNECTED_PARTY_TYPES] = payload[cn.ALL_PARTY_TYPES]\n",
    "            names_source_cols = [\n",
    "                cn.ALL_PARTY_NAMES,\n",
    "                cn.ALL_CONNECTED_PARTIES_NAMES,\n",
    "            ]\n",
    "\n",
    "            payload.update(\n",
    "                {\n",
    "                    cn.CLEANED_NAMES: self.engine.get_clean_names_from_concat_name(\n",
    "                        self.get_field_value_name(fields, cn.CONCAT_ADDRESS),\n",
    "                        {key: payload[key] for key in names_source_cols},\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "            payload.update({cn.CONCAT_RESIDUE: payload[cn.CLEANED_NAMES][cn.CONCAT_RESIDUE]})\n",
    "\n",
    "            concat_residue = payload[cn.CONCAT_RESIDUE]\n",
    "            concat_address = self.get_field_value_name(fields, cn.CONCAT_ADDRESS)\n",
    "\n",
    "            payload.update({cn.CONCAT_ADDRESS_NO_CHANGES: concat_residue == concat_address})\n",
    "            for match in matches:\n",
    "                match[cn.AP_TRIGGERS] = self.engine.set_triggered_tokens_discovery(\n",
    "                    payload, match, fields\n",
    "                )\n",
    "        return payloads\n",
    "\n",
    "    def get_field_value_name(self, fields, name):\n",
    "        try:\n",
    "            return fields.get(name, name).value\n",
    "        except AttributeError:\n",
    "            return None\n",
    "\n",
    "    def get_key(self, payload, match, conf):\n",
    "        new_config = {}\n",
    "        for key, value in dict(conf).items():\n",
    "            temp_dict = dict(value)\n",
    "            for new_key in temp_dict:\n",
    "                for element in temp_dict[new_key]:\n",
    "                    elements = element.split(\".\")\n",
    "                    if cn.MATCH_RECORDS in element:\n",
    "                        value = match\n",
    "                        elements = elements[1:]\n",
    "                    else:\n",
    "                        value = payload\n",
    "\n",
    "                    for field_name in elements:\n",
    "                        if field_name == \"INPUT_FIELD\":\n",
    "                            value = value[0][field_name][elements[-1]].value\n",
    "                            break\n",
    "                        try:\n",
    "                            value = value.get(field_name, None)\n",
    "                        except TypeError:\n",
    "                            key = PayloadLoader.LIST_ELEMENT_REGEX.sub(\"\", field_name)\n",
    "                            ix = int(PayloadLoader.LIST_ELEMENT_REGEX.match(field_name).groups(0))\n",
    "                            value = value[key][ix]\n",
    "                    new_config[elements[-1]] = value\n",
    "        return new_config\n",
    "\n",
    "    def load_agent_config(self, alert_type=\"WM_ADDRESS\"):\n",
    "        alert_config = alert_agents_config[alert_type]\n",
    "        parsed_agent_config = {}\n",
    "        for agent_name, agent_config in dict(alert_config).items():\n",
    "            particular_agent_config = dict(agent_config)\n",
    "            parsed_agent_config[agent_name] = {}\n",
    "            for new_key in particular_agent_config:\n",
    "                parsed_agent_config[agent_name][new_key] = []\n",
    "                for element in particular_agent_config[new_key]:\n",
    "                    elements = element.split(\".\")\n",
    "                    parsed_agent_config[agent_name][new_key].append(elements[-1])\n",
    "        return parsed_agent_config, alert_config\n",
    "\n",
    "    def transform_cleansed_to_application(self, payloads):\n",
    "\n",
    "        for payload in payloads:\n",
    "            matches = payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "            agent_config, yaml_conf = self.load_agent_config()\n",
    "            agent_input_prepended_agent_name_config = (\n",
    "                prepend_agent_name_to_ap_or_wl_or_aliases_key(agent_config)\n",
    "            )\n",
    "\n",
    "            agent_input_agg_col_config = create_agent_input_agg_col_config(\n",
    "                agent_input_prepended_agent_name_config\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                config = self.get_key(payload, match, yaml_conf)\n",
    "                self.engine.sql_to_merge_specific_columns_to_standardized(\n",
    "                    agent_input_prepended_agent_name_config,\n",
    "                    match,\n",
    "                    config,\n",
    "                    False,\n",
    "                )\n",
    "                match.update(\n",
    "                    {\n",
    "                        key: self.flatten(match.get(key))\n",
    "                        for key in match\n",
    "                        if key.endswith(\"_ap\") or key.endswith(\"_wl\")\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                config.update(\n",
    "                    {\n",
    "                        key: self.flatten(match.get(key))\n",
    "                        for key in match\n",
    "                        if key.endswith(\"_ap\") or key.endswith(\"_wl\")\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                self.engine.sql_to_merge_specific_columns_to_standardized(\n",
    "                    agent_input_agg_col_config, match, config, False\n",
    "                )\n",
    "\n",
    "        return payloads\n",
    "\n",
    "    def flatten(self, value):\n",
    "        try:\n",
    "            if isinstance(value[0], list):\n",
    "                value = [item for item in value if item]\n",
    "                if isinstance(value[0], list):\n",
    "                    return [i for item in value for i in self.flatten(item) if item]\n",
    "        except (TypeError, IndexError):\n",
    "            pass\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899b9fd-2291-410e-802b-04ec5314e73b",
   "metadata": {},
   "source": [
    "# Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d20eba4e-fa6b-462b-a548-d8c9bbc255d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'notebooks/sample/alert_in_payload_format.json', 'r') as file:\n",
    "    payload = json.loads(file.read())\n",
    "\n",
    "payload_json = {key: payload[key] for key in sorted(payload)}\n",
    "payload_json = PayloadLoader().load_payload_from_json(payload_json)\n",
    "payload_json = payload_json['alertPayload']\n",
    "\n",
    "\n",
    "payload_json['match_ids'] = [i for i in range(len(payload_json[cn.ALERT_FIELD][cn.MATCH_RECORDS]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bf7bcf5-be42-4cc1-a227-7938c4417b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = payload_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "762ba43f-d0c2-4f59-84a3-9a785d278d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0389df3b-dbbf-442c-a39f-febecd209c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pipelines.ms.ms_pipeline import MSPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ec7eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = JsonProcessingEngine(pipeline_config)\n",
    "pipeline = MSPipeline(engine, config=pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6394d5e2-f737-4001-b6f0-bb06e47d3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = pipeline.transform_standardized_to_cleansed(payload)\n",
    "new_payloads = pipeline.transform_cleansed_to_application(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7112dba-31ca-4758-a029-d9071b8328f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(value):\n",
    "    try:\n",
    "        if isinstance(value[0], list):\n",
    "            value = [item for list_ in value for item in list_ if item]\n",
    "            print(value)\n",
    "            if isinstance(value[0], list):\n",
    "                return [i for item in value for i in flatten(item) if item]\n",
    "    except (TypeError, IndexError):\n",
    "        pass\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d29811-8a47-404f-aa14-ecacb02d3908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02/31/1900', '04/31/1910']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['02/31/1900', '04/31/1910']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten([['02/31/1900', '04/31/1910']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "771fda00-9d27-4a24-8dbe-032638abd17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "match\n",
      "++++++++\n",
      "['02/31/1900', '04/31/1910'] ['MAY 6, 1981']\n",
      "['UNITED STATES OF AMERICA'] ['US']\n",
      "p\n",
      "match\n",
      "++++++++\n",
      "['02/31/1900', '04/31/1910'] ['MAY 6, 1981']\n",
      "['UNITED STATES OF AMERICA'] ['PL']\n"
     ]
    }
   ],
   "source": [
    "for payload in new_payloads:\n",
    "    print('p')\n",
    "    for match in payload['alert']['matchRecords']:\n",
    "        print('match')\n",
    "        print(\"++++++++\")\n",
    "        print(match[\"ap_all_dobs_aggregated\"], match[\"wl_all_dobs_aggregated\"])\n",
    "        try:\n",
    "            print(match[\"ap_all_residencies_aggregated\"], match[\"wl_all_residencies_aggregated\"])\n",
    "        except:\n",
    "            break\n",
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3311f-755c-4467-b2e3-725c5571dcc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## transform standardized to cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5aa5190-3d92-40c2-ba8e-ea97bc1be010",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = pipeline\n",
    "parties = payload[cn.SUPPLEMENTAL_INFO][cn.RELATED_PARTIES][cn.PARTIES]\n",
    "self.flatten_parties(parties)\n",
    "self.parse_input_records(payload)\n",
    "parsed_payloads = self.connect_input_record_with_match_record(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8782f9ee-16e9-465a-a97c-eed4ff4f4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "for payload in parsed_payloads:\n",
    "    matches = payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "    fields = payload[cn.ALERT_FIELD][cn.INPUT_RECORD_HIST][0][\"INPUT_FIELD\"]\n",
    "    for match in matches:\n",
    "        WatchlistExtractor().update_match_with_wl_values(match)\n",
    "        match[cn.TRIGGERED_BY] = self.engine.set_trigger_reasons(\n",
    "            match, self.pipeline_config.FUZZINESS_LEVEL\n",
    "        )\n",
    "        self.engine.set_beneficiary_hits(match)\n",
    "\n",
    "    self.engine.connect_full_names(parties)\n",
    "\n",
    "    self.engine.collect_party_values(parties, payload)\n",
    "    payload[cn.ALL_CONNECTED_PARTY_TYPES] = payload[cn.ALL_PARTY_TYPES]\n",
    "    names_source_cols = [\n",
    "        cn.ALL_PARTY_NAMES,\n",
    "        cn.ALL_CONNECTED_PARTIES_NAMES,\n",
    "    ]\n",
    "\n",
    "    payload.update(\n",
    "        {\n",
    "            cn.CLEANED_NAMES: self.engine.get_clean_names_from_concat_name(\n",
    "                self.get_field_value_name(fields, cn.CONCAT_ADDRESS),\n",
    "                {key: payload[key] for key in names_source_cols},\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "    payload.update({cn.CONCAT_RESIDUE: payload[cn.CLEANED_NAMES][cn.CONCAT_RESIDUE]})\n",
    "\n",
    "    concat_residue = payload[cn.CONCAT_RESIDUE]\n",
    "    concat_address = self.get_field_value_name(fields, cn.CONCAT_ADDRESS)\n",
    "\n",
    "    payload.update({cn.CONCAT_ADDRESS_NO_CHANGES: concat_residue == concat_address})\n",
    "    for match in matches:\n",
    "        match[cn.AP_TRIGGERS] = self.engine.set_triggered_tokens_discovery(\n",
    "            payload, match, fields\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ecf06-a7e4-45a1-81e9-1203ccd1dd73",
   "metadata": {},
   "source": [
    "# Transform standardized to application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5065aa10-ce89-48dd-adc5-4d84fcb9548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for payload in parsed_payloads:\n",
    "            matches = payload[cn.ALERT_FIELD][cn.MATCH_RECORDS]\n",
    "            agent_config, yaml_conf = self.load_agent_config()\n",
    "            agent_input_prepended_agent_name_config = (\n",
    "                prepend_agent_name_to_ap_or_wl_or_aliases_key(agent_config)\n",
    "            )\n",
    "\n",
    "            agent_input_agg_col_config = create_agent_input_agg_col_config(\n",
    "                agent_input_prepended_agent_name_config\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                config = self.get_key(payload, match, yaml_conf)\n",
    "                self.engine.sql_to_merge_specific_columns_to_standardized(\n",
    "                    agent_input_prepended_agent_name_config,\n",
    "                    match,\n",
    "                    config,\n",
    "                    False,\n",
    "                )\n",
    "                match.update(\n",
    "                    {\n",
    "                        key: self.flatten(match.get(key))\n",
    "                        for key in match\n",
    "                        if key.endswith(\"_ap\") or key.endswith(\"_wl\")\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                config.update(\n",
    "                    {\n",
    "                        key: self.flatten(match.get(key))\n",
    "                        for key in match\n",
    "                        if key.endswith(\"_ap\") or key.endswith(\"_wl\")\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                self.engine.sql_to_merge_specific_columns_to_standardized(\n",
    "                    agent_input_agg_col_config, match, config, False\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a626d1-bac1-41e3-ae8a-cf91c32d99ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "190aa3c5-9909-4b36-b627-b72f22a7e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "match\n",
      "++++++++\n",
      "['02/31/1900', '04/31/1910'] ['MAY 6, 1981']\n",
      "['UNITED STATES OF AMERICA'] ['US']\n",
      "p\n",
      "match\n",
      "++++++++\n",
      "['02/31/1900', '04/31/1910'] ['MAY 6, 1981']\n",
      "['UNITED STATES OF AMERICA'] ['PL']\n"
     ]
    }
   ],
   "source": [
    "for payload in new_payloads:\n",
    "    print('p')\n",
    "    for match in payload['alert']['matchRecords']:\n",
    "        print('match')\n",
    "        print(\"++++++++\")\n",
    "        print(match[\"ap_all_dobs_aggregated\"], match[\"wl_all_dobs_aggregated\"])\n",
    "        try:\n",
    "            print(match[\"ap_all_residencies_aggregated\"], match[\"wl_all_residencies_aggregated\"])\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd453f2-9b7a-4f98-b01f-ad69eb747fa8",
   "metadata": {},
   "source": [
    "# Merge json into \"json format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43bdc10b-5297-431e-9831-5b2a7e36f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tests/shared/parsed_payload.pkl\", \"wb\") as f:\n",
    "    pickle.dump(new_payloads, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea48ac-d227-414c-a898-afaa178bb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "def return_key(dict_, prefix):\n",
    "    \n",
    "    if isinstance(dict_, list):\n",
    "        for num, i in enumerate(dict_):\n",
    "            return_key(i, prefix +f\"[{num}]\")\n",
    "        return\n",
    "    if isinstance(dict_, str) or dict_ is None:\n",
    "        new_dict[prefix] = dict_\n",
    "        return\n",
    "\n",
    "    for key in dict_:\n",
    "        if prefix:\n",
    "            basic_prefix = prefix + \".\" + key\n",
    "        else:\n",
    "            basic_prefix = key\n",
    "        return_key(dict_[key], basic_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f09dca-53cb-4d37-9b2e-c33297c7c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_key(payload, \"\")\n",
    "\n",
    "with open(f'notebooks/sample/alert_in_payload_format.json', 'w') as file:\n",
    "    json.dump(new_dict ,file)\n",
    "\n",
    "payload_json = PayloadLoader().load_payload_from_json(new_dict)\n",
    "\n",
    "payload_json == payload\n",
    "\n",
    "with open(f'notebooks/sample/alert.json', 'r') as file:\n",
    "    payload = json.loads(file.read())\n",
    "\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab4efc-6443-4c89-a3f3-e4a4cef2a701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
